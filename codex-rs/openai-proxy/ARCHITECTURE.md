# Codex OpenAI Proxy æ¶æ„æ–‡æ¡£

## ğŸ“‹ æ ¸å¿ƒéœ€æ±‚ï¼ˆCRITICAL - å¿…é¡»ç†è§£ï¼‰

**æˆ‘ä»¬çš„çœŸæ­£éœ€æ±‚æ˜¯ä»€ä¹ˆï¼Ÿ**

```
Cursor IDE
    â†“ å‘é€ OpenAI API è¯·æ±‚
codex-openai-proxyï¼ˆæˆ‘ä»¬çš„ä»£ç†ï¼‰
    â†“ è½¬æ¢æ ¼å¼ + ä½¿ç”¨ Codex ç™»å½•çš„ ChatGPT Plus è´¦å·
Codex CLIï¼ˆçº¯è½¬å‘å™¨ï¼Œä¸æ‰§è¡Œä»»ä½•å·¥å…·ï¼‰
    â†“ ä½¿ç”¨å·²ç™»å½•çš„è´¦å·
OpenAI å®˜æ–¹ API Server
    â†“ è¿”å› LLM å“åº”ï¼ˆå¯èƒ½åŒ…å« tool_callsï¼‰
Codex CLI
    â†“ è½¬å‘åŸå§‹å“åº”
codex-openai-proxy
    â†“ é€‚é…æˆ OpenAI API æ ¼å¼
Cursor IDE
    â†“ åœ¨æœ¬åœ°æ‰§è¡Œå·¥å…·ï¼ˆå¦‚æœæœ‰ tool_callsï¼‰
    â†“ å°†å·¥å…·ç»“æœä½œä¸ºä¸‹ä¸€æ¡æ¶ˆæ¯å‘é€å›ä»£ç†
```

## âš ï¸ å…³é”®ç†è§£ï¼ˆä¹‹å‰æé”™çš„åœ°æ–¹ï¼‰

### âŒ é”™è¯¯ç†è§£ï¼ˆå¯¼è‡´æ— é™å¾ªç¯ï¼‰

ä¹‹å‰æˆ‘ä»¬è¯¯ä»¥ä¸ºéœ€è¦ Codex **ä½œä¸º Agent æ‰§è¡Œå·¥å…·**ï¼š

```rust
// âŒ é”™è¯¯çš„æ–¹å¼
sandbox_policy: SandboxPolicy::Unrestricted,  // å…è®¸ Codex æ‰§è¡Œå·¥å…·
approval_policy: AskForApproval::Never,       // è‡ªåŠ¨æ‰§è¡Œ

// ç»“æœï¼š
// Codex è‡ªå·±æ‰§è¡Œå·¥å…· â†’ å·¥å…·å¤±è´¥ â†’ Codex é‡è¯• â†’ æ— é™å¾ªç¯
// 20+ æ¬¡ tool_callsï¼Œä»ä¸è¿”å›æœ€ç»ˆç­”æ¡ˆ
```

### âœ… æ­£ç¡®ç†è§£ï¼ˆçº¯è½¬å‘ï¼‰

æˆ‘ä»¬å®é™…éœ€è¦çš„æ˜¯ Codex **çº¯è½¬å‘ API**ï¼š

```rust
// âœ… æ­£ç¡®çš„æ–¹å¼
sandbox_policy: SandboxPolicy::ReadOnly,  // Codex ä¸æ‰§è¡Œå·¥å…·ï¼Œåªè½¬å‘
approval_policy: AskForApproval::Never,   // ä¸éœ€è¦å®¡æ‰¹

// ç»“æœï¼š
// Codex åªåšè½¬å‘ â†’ OpenAI è¿”å› tool_calls â†’ è½¬å‘ç»™ Cursor
// Cursor æœ¬åœ°æ‰§è¡Œå·¥å…· â†’ å°†ç»“æœå‘å›
```

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### 1. ä¸ºä»€ä¹ˆä½¿ç”¨ Codexï¼Ÿ

**Codex çš„å”¯ä¸€ä½œç”¨ï¼šä½¿ç”¨å·²ç™»å½•çš„ ChatGPT Plus è´¦å·è®¿é—® OpenAI API**

- Codex CLI é€šè¿‡ `codex login` å·²ç»ç™»å½•äº† ChatGPT Plus
- å®ƒå¯ä»¥ä½¿ç”¨è¿™ä¸ªç™»å½•çŠ¶æ€è®¿é—® OpenAI API
- æˆ‘ä»¬çš„ä»£ç†åˆ©ç”¨ Codex çš„è®¤è¯ï¼Œé¿å…ç›´æ¥ç®¡ç† API keys

### 2. ä¸ºä»€ä¹ˆä½¿ç”¨ ThreadManager è€Œä¸æ˜¯ ModelClientï¼Ÿ

**æœ€åˆå°è¯•äº† ModelClientï¼Œä½†é‡åˆ°ç¼–è¯‘é—®é¢˜ï¼š**

```rust
// å°è¯•ä½¿ç”¨ ModelClientï¼ˆå¤±è´¥ï¼‰
use codex_core::ModelClient;
use codex_core::client_common::Prompt;  // âŒ private module
use codex_otel::OtelManager;            // âŒ unresolved import
use codex_core::model_provider_info::ModelProviderInfo;  // âŒ private module
```

**æ”¹ç”¨ ThreadManagerï¼ˆæˆåŠŸï¼‰ï¼š**

```rust
// ThreadManager æ˜¯å…¬å¼€ API
use codex_core::ThreadManager;
use codex_core::CodexThread;
```

### 3. ReadOnly çš„ä½œç”¨

```rust
sandbox_policy: SandboxPolicy::ReadOnly,
```

**ReadOnly ç¡®ä¿ï¼š**
- Codex ä¸ä¼šåœ¨æœåŠ¡å™¨ç«¯æ‰§è¡Œå·¥å…·
- åªè½¬å‘ OpenAI API çš„åŸå§‹å“åº”
- å¦‚æœ API è¿”å› tool_callsï¼Œç›´æ¥è½¬å‘ç»™ Cursor
- Cursor åœ¨æœ¬åœ°ï¼ˆç”¨æˆ·çš„æœºå™¨ï¼‰æ‰§è¡Œå·¥å…·

**å¯¹æ¯”ï¼š**
- `Unrestricted` - Codex è‡ªå·±æ‰§è¡Œå·¥å…·ï¼ˆå¯¼è‡´æ— é™å¾ªç¯ï¼‰
- `ReadOnly` - Codex åªè½¬å‘ï¼Œä¸æ‰§è¡Œ

## ğŸ“ æ ¸å¿ƒä»£ç è¯´æ˜

### å…³é”®é…ç½®

```rust
// åœ¨ get_or_create_thread å’Œ Submission ä¸­éƒ½è¦è®¾ç½®
let overrides = vec![
    ("model".to_string(), toml::Value::String(map_model(model))),
    ("approval_policy".to_string(), toml::Value::String("never".to_string())),
    ("sandbox_mode".to_string(), toml::Value::String("read-only".to_string())),  // âš ï¸ å…³é”®
];

let submission = Submission {
    op: Op::UserTurn {
        approval_policy: AskForApproval::Never,
        sandbox_policy: SandboxPolicy::ReadOnly,  // âš ï¸ å…³é”®
        // ...
    },
};
```

### æ¨¡å‹åç§°åè½¬

```rust
fn map_model(model: &str) -> String {
    // Cursor ä½¿ç”¨åè½¬çš„æ¨¡å‹å
    // ä¾‹å¦‚ï¼šCursor å‘é€ "2.5-tpg"
    // æˆ‘ä»¬åè½¬æˆ "gpt-5.2" å‘é€ç»™ Codex
    model.chars().rev().collect()
}
```

**ä¸ºä»€ä¹ˆåè½¬ï¼Ÿ**
- Cursor å…è®¸è‡ªå®šä¹‰æ¨¡å‹å
- ç”¨æˆ·åœ¨ Cursor ä¸­è¾“å…¥åè½¬çš„åå­—ï¼ˆå¦‚ "xedoc-2.5-tpg"ï¼‰
- ä»£ç†åè½¬å›æ­£å¸¸åå­—ï¼ˆ"gpt-5.2-codex"ï¼‰å‘ç»™ Codex

### å“åº”æ ¼å¼è¦ç‚¹

```rust
let resp = ChatCompletionResponse {
    model: original_model.clone(),  // âš ï¸ ä½¿ç”¨åŸå§‹æ¨¡å‹åï¼Œä¸è¦ç”¨åè½¬åçš„
    choices: vec![ChatChoice {
        message: ChatMessageResponse {
            content: final_text,
            tool_calls: if tool_calls.is_empty() { None } else { Some(tool_calls) },
        },
        finish_reason: if !tool_calls.is_empty() {
            "tool_calls".to_string()  // âš ï¸ æœ‰å·¥å…·è°ƒç”¨æ—¶å¿…é¡»æ˜¯ "tool_calls"
        } else {
            "stop".to_string()
        },
    }],
};
```

## ğŸ› å¸¸è§é”™è¯¯åŠè§£å†³æ–¹æ¡ˆ

### é”™è¯¯ 1: å†…å®¹é‡å¤å‘é€

**é—®é¢˜ï¼š**
```rust
EventMsg::TurnComplete(done) => {
    if let Some(msg) = done.last_agent_message {
        let chunk = stream_chunk(Some(&msg), ...);  // âŒ é‡å¤å‘é€
        tx.send(Ok(chunk)).await;
    }
}
```

**åŸå› ï¼š**
- å†…å®¹å·²ç»é€šè¿‡ `AgentMessageDelta` å‘é€è¿‡äº†
- åœ¨ TurnComplete å†æ¬¡å‘é€å¯¼è‡´ Cursor æ£€æµ‹åˆ° "looping"

**è§£å†³ï¼š**
```rust
EventMsg::TurnComplete(_done) => {
    // âš ï¸ ä¸è¦å†å‘é€ last_agent_message
    // åªå‘é€ finish_reason
    let chunk = stream_chunk_with_finish(None, None, finish_reason, model);
    tx.send(Ok(chunk)).await;
}
```

### é”™è¯¯ 2: ç¼ºå°‘ model å­—æ®µ

**é—®é¢˜ï¼š**
```
Cursor æ˜¾ç¤º "Connection Error" ä½†è¿”å› 200
```

**åŸå› ï¼š**
å“åº”çš„ chunk ä¸­ç¼ºå°‘ `model` å­—æ®µ

**è§£å†³ï¼š**
```rust
serde_json::json!({
    "model": model,  // âš ï¸ æ¯ä¸ª chunk éƒ½å¿…é¡»åŒ…å«
    "choices": [...]
})
```

### é”™è¯¯ 3: æ— é™å·¥å…·è°ƒç”¨å¾ªç¯

**é—®é¢˜ï¼š**
```
Codex è¿ç»­ 20+ æ¬¡è°ƒç”¨å·¥å…·ï¼Œä»ä¸è¿”å›æœ€ç»ˆç­”æ¡ˆ
```

**åŸå› ï¼š**
```rust
sandbox_policy: SandboxPolicy::Unrestricted  // âŒ é”™è¯¯
```

**è§£å†³ï¼š**
```rust
sandbox_policy: SandboxPolicy::ReadOnly  // âœ… æ­£ç¡®
```

## ğŸ“Š ç§¯ç´¯çš„ç»éªŒæ•™è®­

### âœ… å¿…é¡»ä¿ç•™çš„ç‰¹æ€§

1. **åŒè·¯ç”±æ”¯æŒ** - `/v1/*` å’Œ `/*` éƒ½è¦æ”¯æŒï¼ˆCursor å…¼å®¹æ€§ï¼‰
2. **æ¨¡å‹åç§°åè½¬** - `map_model()` å‡½æ•°
3. **ä¿ç•™åŸå§‹æ¨¡å‹å** - å“åº”ä¸­ä½¿ç”¨ `original_model`ï¼Œä¸ç”¨åè½¬åçš„
4. **ä¸é‡å¤å‘é€å†…å®¹** - TurnComplete æ—¶åªå‘é€ `finish_reason`
5. **model å­—æ®µå¿…é¡»åŒ…å«** - æ¯ä¸ª streaming chunk éƒ½è¦æœ‰
6. **CORS å®Œæ•´æ”¯æŒ** - `allow_origin(Any)`
7. **æ—¥å¿—ç³»ç»Ÿ** - `LOG_CHANNEL` + `/logs` ç«¯ç‚¹
8. **Reasoning æ£€æµ‹** - è®°å½• reasoning items
9. **conversation_id** - æ”¯æŒæŒä¹…åŒ–å¯¹è¯
10. **ReadOnly æ²™ç®±** - ç¡®ä¿ Codex ä¸æ‰§è¡Œå·¥å…·

### âŒ å¸¸è§é™·é˜±

1. **ä¸è¦ä½¿ç”¨ Unrestricted** - ä¼šå¯¼è‡´å·¥å…·æ‰§è¡Œå¾ªç¯
2. **ä¸è¦é‡å¤å‘é€å†…å®¹** - ä¼šè¢« Cursor æ£€æµ‹ä¸º looping
3. **ä¸è¦å¿˜è®° model å­—æ®µ** - ä¼šå¯¼è‡´è¿æ¥é”™è¯¯
4. **ä¸è¦æ··æ·†æ¨¡å‹å** - å“åº”è¦ç”¨åŸå§‹åï¼Œä¸è¦ç”¨åè½¬å
5. **ä¸è¦å°è¯•ä½¿ç”¨ ModelClient** - API ä¸å¤Ÿç¨³å®šï¼Œç”¨ ThreadManager

## ğŸ§ª æµ‹è¯•è¦ç‚¹

### 1. åŸºæœ¬æµ‹è¯•
```bash
# å¯åŠ¨ä»£ç†
cargo run --release

# åœ¨ Cursor ä¸­é…ç½®
# Base URL: https://codex.wenming-dev.org
# Model: xedoc-2.5-tpg
```

### 2. æ£€æŸ¥è¦ç‚¹

**æ—¥å¿—æ£€æŸ¥ï¼ˆhttp://127.0.0.1:11435/logsï¼‰ï¼š**
```json
{"type": "incoming_request", "model": "xedoc-2.5-tpg"}
{"type": "codex_forward", "mapped_model": "gpt-5.2-codex"}
{"type": "reasoning_detected", "summary_count": 1}
{"type": "cursor_response", "finish_reason": "stop"}
```

**ä¸åº”è¯¥çœ‹åˆ°ï¼š**
```json
{"type": "tool_call_forwarded"}  // é™¤é LLM çœŸçš„è¿”å›äº† tool_calls
{"type": "stream_codex_error"}   // ä¸åº”è¯¥æœ‰é”™è¯¯
```

### 3. å·¥å…·è°ƒç”¨æµ‹è¯•

**æ­£ç¡®çš„æµç¨‹ï¼š**
```
1. Cursor å‘é€è¯·æ±‚ "åˆ—å‡ºå½“å‰ç›®å½•çš„æ–‡ä»¶"
2. Proxy è½¬å‘ç»™ Codex â†’ OpenAI
3. OpenAI è¿”å› tool_calls: [{"name": "list_dir", ...}]
4. Proxy è½¬å‘ç»™ Cursor
5. Cursor æœ¬åœ°æ‰§è¡Œ list_dir
6. Cursor å°†ç»“æœå‘é€å› Proxy
7. å¾ªç¯ç›´åˆ° LLM è¿”å›æœ€ç»ˆç­”æ¡ˆ
```

**ä¸åº”è¯¥çœ‹åˆ°ï¼š**
```
- 20+ æ¬¡è¿ç»­ tool_calls
- Codex è‡ªå·±æ‰§è¡Œå·¥å…·
- å·¥å…·æ‰§è¡Œå¤±è´¥ä½†ä¸€ç›´é‡è¯•
```

## ğŸ“‚ æ–‡ä»¶ç»“æ„

```
codex-rs/openai-proxy/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.rs                      # ä¸»ä»£ç†é€»è¾‘ï¼ˆâš ï¸ ä½¿ç”¨ ReadOnlyï¼‰
â”‚   â”œâ”€â”€ main_threadmanager_backup.rs # æ—§ç‰ˆæœ¬å¤‡ä»½
â”‚   â””â”€â”€ main_modelclient.rs          # ModelClient å°è¯•ï¼ˆç¼–è¯‘å¤±è´¥ï¼‰
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ logs.html                    # æ—¥å¿—æŸ¥çœ‹å™¨
â”‚   â”œâ”€â”€ logs.css
â”‚   â””â”€â”€ logs.js
â”œâ”€â”€ Cargo.toml
â”œâ”€â”€ STATUS.md                        # çŠ¶æ€æ–‡æ¡£
â”œâ”€â”€ REASONING.md                     # Reasoning æ”¯æŒåˆ†æ
â””â”€â”€ ARCHITECTURE.md                  # æœ¬æ–‡ä»¶
```

## ğŸš€ éƒ¨ç½²é…ç½®

### Cloudflare Tunnel é…ç½®

**C:\Users\wenming\.cloudflared\config.yaml:**
```yaml
tunnel: <tunnel-id>
credentials-file: C:\Users\wenming\.cloudflared\<tunnel-id>.json

ingress:
  - hostname: codex.wenming-dev.org
    service: http://localhost:11435
    originRequest:
      protocol: http2  # âš ï¸ å¼ºåˆ¶ HTTP/2ï¼Œä¸ç”¨ QUICï¼ˆç½‘ç»œé™åˆ¶ï¼‰
  - service: http_status:404
```

### ç¯å¢ƒå˜é‡

```bash
# å¯é€‰ï¼šè‡ªå®šä¹‰ç›‘å¬åœ°å€
export CODEX_OPENAI_PROXY_ADDR=127.0.0.1:11435
```

### Codex é…ç½®

**C:\Users\wenming\.codex\config.toml:**
```toml
model = "gpt-5.2-codex"
model_reasoning_effort = "high"
model_verbosity = "medium"  # âš ï¸ å¿…é¡»è®¾ç½®ï¼Œé»˜è®¤ "low" ä¸æ”¯æŒ
```

## ğŸ”„ å·¥ä½œæµç¨‹æ€»ç»“

### è¯·æ±‚æµç¨‹
```
1. Cursor å‘é€ ChatCompletionRequest
   - model: "xedoc-2.5-tpg"
   - messages: [{"role": "user", "content": "..."}]

2. Proxy å¤„ç†
   - åè½¬æ¨¡å‹å: "xedoc-2.5-tpg" â†’ "gpt-5.2-codex"
   - åˆ›å»º Submission (ReadOnly)
   - æäº¤ç»™ CodexThread

3. Codex è½¬å‘
   - ä½¿ç”¨ç™»å½•çš„ ChatGPT Plus è´¦å·
   - è°ƒç”¨ OpenAI API
   - è·å–å“åº”æµ

4. Proxy é€‚é…
   - æ”¶é›† ResponseItems
   - è½¬æ¢æˆ OpenAI æ ¼å¼
   - æ£€æµ‹ tool_calls
   - è½¬å‘ç»™ Cursor

5. Cursor å¤„ç†
   - å¦‚æœæœ‰ tool_callsï¼Œåœ¨æœ¬åœ°æ‰§è¡Œ
   - å°†ç»“æœä½œä¸ºä¸‹ä¸€æ¡æ¶ˆæ¯å‘é€
   - å¦‚æœæ²¡æœ‰ tool_callsï¼Œæ˜¾ç¤ºæœ€ç»ˆç­”æ¡ˆ
```

## ğŸ“ è”ç³»ä¸ç»´æŠ¤

**é‡è¦æé†’ï¼š**
- è¿™ä¸ªä»£ç†æ˜¯**çº¯è½¬å‘**æ¨¡å¼
- Codex ä¸æ‰§è¡Œä»»ä½•å·¥å…·
- æ‰€æœ‰å·¥å…·éƒ½åœ¨ Cursor æœ¬åœ°æ‰§è¡Œ
- å¦‚æœçœ‹åˆ°å·¥å…·æ‰§è¡Œå¾ªç¯ï¼Œæ£€æŸ¥ `SandboxPolicy`

**å…³é”®é…ç½®å¿…é¡»æ˜¯ï¼š**
```rust
sandbox_policy: SandboxPolicy::ReadOnly,
sandbox_mode: "read-only",
```

**ç»å¯¹ä¸è¦æ”¹æˆï¼š**
```rust
sandbox_policy: SandboxPolicy::Unrestricted,  // âŒ ä¼šå¯¼è‡´å¾ªç¯
```
